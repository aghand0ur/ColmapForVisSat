{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALIQaraaounReservoir.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aghand0ur/ColmapForVisSat/blob/master/ALIQaraaounReservoir_CDSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Yv_nmDol1Y"
      },
      "source": [
        "#**Pre-requiremnts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL1t--8ckj0J"
      },
      "source": [
        "import matplotlib as mpl\n",
        "mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGBmw38Skl9F"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLG08CY7kohG"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from shapely.geometry import shape\n",
        "from shapely.wkt import loads\n",
        "\n",
        "import urllib.request as request\n",
        "import json\n",
        "from astropy.table import Table\n",
        "from tabulate import tabulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vKq19s4kqwM"
      },
      "source": [
        "#clone the Github repository where all required python scripts exist\n",
        "%cd /content/\n",
        "#!git clone https://github.com/sentinel-hub/water-observatory-backend.git\n",
        "#!git clone https://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@github.com/Geospatial-Earth-Observation-Group/qaraaoun-reservoir-backend.git\n",
        "!git clone https://aghand0ur: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@github.com/geoaigroup/qaraaoun-reservoir-backend.git\n",
        "\n",
        "#import sys\n",
        "#print(sys.path)\n",
        "#sys.path.append(\"water-observatory-backend/src\")\n",
        "#sys.path.append(\"qaraaoun-reservoir-backend/src\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp9pax8Q9ass"
      },
      "source": [
        "#push changes to the organization private repo using my github token\n",
        "#To be used only one time to move all the files to github\n",
        "#!git config --global user.email \"ghandour.aub@gmail.com\"\n",
        "#!git config --global user.name \"aghand0ur\"\n",
        "\n",
        "#!git remote set-url origin https://df9ff100fd97b8c39cfdb90ec7ea83f5741516da@github.com/Geospatial-Earth-Observation-Group/qaraaoun-reservoir.git\n",
        "\n",
        "#!git add .\n",
        "#!git commit -m \"first push\"\n",
        "#!git push -u origin main\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ9mB51GktBa"
      },
      "source": [
        "!#installing all requirements\n",
        "!pip install sentinelhub==3.6.3\n",
        "!pip install geopandas\n",
        "!pip install rasterio\n",
        "#!pip install s2cloudless\n",
        "!pip install recordclass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#putting configuration's instance ID into sentinelhub package's configuration file\n",
        "import sentinelhub\n",
        "print(sentinelhub.__version__)\n",
        "# !sentinelhub.config --instance_id 085f5b94-26c7-4d88-b472-910df06e62f1\n",
        "#!sentinelhub.config --instance_id e8ec9b27-150d-4c87-b6df-7d4933534c78\n",
        "!sentinelhub.config --instance_id c8d67966-ddd8-4d29-a3e6-e75d342218e8\n",
        "!sentinelhub.config --show\n",
        "\n",
        "from oauthlib.oauth2 import BackendApplicationClient\n",
        "from requests_oauthlib import OAuth2Session\n",
        "from sentinelhub import SHConfig\n",
        "\n",
        "# Your client credentials\n",
        "client_id = 'sh-76406cb6-3b67-46bf-b39a-260b1e7b7413'\n",
        "client_secret = 'GJ8JAOM7VNnKfMKDSJRlP0WbrQm8A0bZ'\n",
        "\n",
        "# Create a session\n",
        "# client = BackendApplicationClient(client_id=client_id)\n",
        "# oauth = OAuth2Session(client=client)\n",
        "\n",
        "# Get token for the session\n",
        "# token = oauth.fetch_token(token_url='https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token',\n",
        "#                           client_secret=client_secret)\n",
        "\n",
        "# All requests using this session will have an access token automatically added\n",
        "#resp = oauth.get(\"...\")\n",
        "#print(resp.content)\n",
        "config = SHConfig()\n",
        "\n",
        "config.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
        "config.sh_client_id = client_id\n",
        "config.sh_client_secret = client_secret\n",
        "config.sh_client_id = client_id\n",
        "config.sh_client_secret = client_secret\n",
        "config.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n",
        "config.instance_id = \"c8d67966-ddd8-4d29-a3e6-e75d342218e8\"\n",
        "config.save()\n",
        "\n",
        "!sentinelhub.config --show"
      ],
      "metadata": {
        "id": "xAbKlU77js97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j0z5Sm3kyAv"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/qaraaoun-reservoir-backend/src')\n",
        "\n",
        "#importing necessary packages\n",
        "from visualisation import plot_water_body, plot_water_body\n",
        "from geom_utils import get_bbox, get_optimal_resolution\n",
        "from sh_requests import get_optical_data, get_S2_request, get_S2_wmsrequest\n",
        "from s2_water_extraction import extract_surface_water_area_per_frame_MNDWI, surface_water_area_with_dem_veto_MNDWI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuZIvCH_oq99"
      },
      "source": [
        "#**Qaraaoun-Reservoir**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-lzoelVk0IA"
      },
      "source": [
        "#identifying the surface area of the qaraaoun reservoir when it is full(shapefile)\n",
        "#the Json data present in the url is been analyzed using json.load()\n",
        "wb_url = 'https://water.blue-dot-observatory.com/api/waterbodies/38784/index.html'\n",
        "url=request.urlopen(wb_url)\n",
        "wb_data=json.loads(url.read())\n",
        "nominal_outline = shape(wb_data['nominal_outline']['geometry'])\n",
        "nominal_outline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNJyPLHRk2L7"
      },
      "source": [
        "#getting the estimated water level\n",
        "#date=datetime(2021,3,16)\n",
        "#date=datetime(2015,8,30)\n",
        "date=datetime(2019,3,22)\n",
        "#date=datetime(2020,5,10)\n",
        "the_dam_bbox = get_bbox(nominal_outline)\n",
        "resx, resy = get_optimal_resolution(the_dam_bbox)\n",
        "measurements = extract_surface_water_area_per_frame_MNDWI(42, nominal_outline, the_dam_bbox, date, resx, resy)\n",
        "\n",
        "measurement_with_dem = surface_water_area_with_dem_veto_MNDWI(measurements, nominal_outline, the_dam_bbox, resx, resy, 15)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrc58UiBuw_X"
      },
      "source": [
        "print(\"The Preliminary result:\"+f'{measurements.SURF_WATER_LEVEL}')\n",
        "print(\"The more accurate result:\"+f'{measurement_with_dem.SURF_WATER_LEVEL}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMY6V7Gtk4ri"
      },
      "source": [
        "detected_water=loads(measurements.GEOMETRY)\n",
        "type(detected_water)\n",
        "print(\"True Color preliminary result\")\n",
        "plot_water_body(get_optical_data(get_S2_request('TRUE-COLOR-S2-L1C',the_dam_bbox,date,resx, resy, 0.2)),\n",
        "                date, nominal_outline, the_dam_bbox, detected_water, measurements.SURF_WATER_LEVEL,color_nominal='Blue',add_text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tap_lBtoAIo"
      },
      "source": [
        "print(\"MNDWI-S2-L1C Preliminary result\")\n",
        "plot_water_body(get_optical_data(get_S2_request('MNDWI-S2-L1C',the_dam_bbox,date,resx, resy, 0.2)),\n",
        "                date, nominal_outline, the_dam_bbox, detected_water, measurements.SURF_WATER_LEVEL,color_nominal='Blue',add_text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQj9qtkPoMWi"
      },
      "source": [
        "detected_water_with_dem = loads(measurement_with_dem.GEOMETRY)\n",
        "print(\"More accurate True Color Preliminary result\")\n",
        "plot_water_body(get_optical_data(get_S2_request('TRUE-COLOR-S2-L1C',the_dam_bbox,date,resx, resy, 0.2)),\n",
        "                date, nominal_outline, the_dam_bbox,detected_water_with_dem, measurement_with_dem.SURF_WATER_LEVEL,color_nominal='Blue',add_text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ty7PkbIoaYF"
      },
      "source": [
        "print(\"More accurate MNDWI-S2-L1C Preliminary result\")\n",
        "plot_water_body(get_optical_data(get_S2_request('MNDWI-S2-L1C',the_dam_bbox,date,resx, resy, 0.2)),\n",
        "                date, nominal_outline, the_dam_bbox,detected_water_with_dem, measurement_with_dem.SURF_WATER_LEVEL,color_nominal='Blue',add_text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTZXyDGQo4-O"
      },
      "source": [
        "#**Measurements for all dates**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inrEKRSdxL3r"
      },
      "source": [
        "#Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UVPMjd_pEdx"
      },
      "source": [
        "\"\"\"\n",
        "#looping over all the dates in the json file of the reservoir\n",
        "#mount to your google drive and create a new folder with Resulted_images as its name\n",
        "Results=[]\n",
        "dates=[]\n",
        "#os.chdir(\"gdrive/My Drive/CNRS/hdd/Qaraaoun\")\n",
        "for measurement in wb_data['measurements']:\n",
        "  y=measurement['date']\n",
        "  date=datetime.strptime(y, '%Y-%m-%d')\n",
        "  sentinell_image=get_S2_request('TRUE-COLOR-S2-L1C',the_dam_bbox,date,resx, resy, 0.2)\n",
        "  if len(sentinell_image.get_data())>0:\n",
        "    measurements = extract_surface_water_area_per_frame(42, nominal_outline, the_dam_bbox, date, resx, resy)\n",
        "    measurements_with_dem = surface_water_area_with_dem_veto(measurements, nominal_outline, the_dam_bbox, resx, resy, 15)\n",
        "    detected_water_with_dem = loads(measurements_with_dem.GEOMETRY)\n",
        "    plot_water_body(get_optical_data(sentinell_image),\n",
        "                    date, nominal_outline, the_dam_bbox,detected_water_with_dem, measurements_with_dem.SURF_WATER_LEVEL,color_nominal='Blue',add_text=True,file_name=f'{date}'\".png\")\n",
        "    Results.append(measurements_with_dem.SURF_WATER_LEVEL)\n",
        "    dates.append(y)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJfghZOVpvg1"
      },
      "source": [
        "#storing results in a tabe\n",
        "#results_by_table=Table([dates,Results], names=('dates','Results'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzGrLqyrp6bL"
      },
      "source": [
        "\"\"\"\n",
        "#storing measurements in a csv file\n",
        "filename = \"gdrive/My Drive/CNRS/hdd/Qaraaoun/WaterDetection\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "g = open('%s.csv' % filename, 'a')\n",
        "#g=open('gdrive/My Drive/CNRS/hdd/Qaraaoun/results2.csv,'a')\n",
        "g.write(tabulate(results_by_table))\n",
        "g.close()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk2KefwtIdZh"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "#Use for debugginh purpose\n",
        "#to be removed later on\n",
        "import geopandas as gpd\n",
        "sensor_water_level=858.12\n",
        "\n",
        "bathymetry = gpd.read_file('/content/qaraaoun-reservoir/src/models/bathymetric.shp')\n",
        "detected_water=loads(measurements.GEOMETRY)\n",
        "#type(detected_water)\n",
        "#type(bathymetry)\n",
        "#bathymetry['geometry']\n",
        "print(bathymetry[\"surface\"].sum())\n",
        "gdf_detected_water=bathymetry.copy()\n",
        "intersection=bathymetry['geometry'].intersection(detected_water)\n",
        "gdf_detected_water['geometry']=intersection\n",
        "\n",
        "#gdf_detected_water.crs\n",
        "#EPSG:32636\n",
        "#WGS 84 / UTM zone 36N\n",
        "gdf_detected_water=gdf_detected_water.to_crs(32636)\n",
        "\n",
        "gdf_detected_water['surface'] = gdf_detected_water['geometry'].area\n",
        "gdf_detected_water['volume']=(sensor_water_level - gdf_detected_water['moydepth'])*gdf_detected_water['surface']\n",
        "#print(gdf_detected_water['volume'].sum())\n",
        "gdf_detected_water.to_file('/content/qaraaoun-reservoir/src/models/result2.shp')\n",
        "\n",
        "#gdf_detected_water\n",
        "print(gdf_detected_water[\"surface\"].sum())\n",
        "print(gdf_detected_water[\"volume\"].sum())\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj88ktVFckrk"
      },
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import time\n",
        "bathymetry = gpd.read_file('/content/qaraaoun-reservoir/src/models/bathymetric.shp')\n",
        "df_sensor_water_level = pd.read_excel('/content/qaraaoun-reservoir/src/models/sensor_water_level.xlsx')\n",
        "#df_sensor_water_level\n",
        "\n",
        "Results=[]\n",
        "dates=[]\n",
        "#os.chdir(\"gdrive/My Drive/CNRS/hdd/Qaraaoun\")\n",
        "for measurement in wb_data['measurements']:\n",
        "  y=measurement['date']\n",
        "  date=datetime.strptime(y, '%Y-%m-%d')\n",
        "  #print(date)\n",
        "\n",
        "  sensor_water_level = df_sensor_water_level.loc[df_sensor_water_level.Date == date, 'WaterLevel']\n",
        "\n",
        "  if len(sensor_water_level) != 1:\n",
        "    continue\n",
        "\n",
        "  sensor_water_level = sensor_water_level.item()\n",
        "  if sensor_water_level > 0:\n",
        "    #print(sensor_water_level)\n",
        "    sentinell_image=get_S2_request('TRUE-COLOR-S2-L1C',the_dam_bbox,date,resx, resy, 0.2)\n",
        "    if len(sentinell_image.get_data())>0:\n",
        "      try:\n",
        "        measurements = extract_surface_water_area_per_frame(42, nominal_outline, the_dam_bbox, date, resx, resy)\n",
        "        detected_water=loads(measurements.GEOMETRY)\n",
        "\n",
        "        #export detected water region as json file to be used in the front-end\n",
        "        detected_water_dict = gpd.GeoSeries([detected_water]).__geo_interface__\n",
        "        date_formated = date.strftime(\"%Y-%m-%d\")\n",
        "        with open('gdrive/My Drive/CNRS/hdd/Qaraaoun/temp/%s.json' % date_formated, 'w') as fp:\n",
        "          json.dump(detected_water_dict, fp)\n",
        "\n",
        "\n",
        "\n",
        "        #measurements_with_dem = surface_water_area_with_dem_veto(measurements, nominal_outline, the_dam_bbox, resx, resy, 15)\n",
        "        #detected_water_with_dem = loads(measurements_with_dem.GEOMETRY)\n",
        "        #plot_water_body(get_optical_data(sentinell_image),\n",
        "                      #date, nominal_outline, the_dam_bbox,detected_water_with_dem, measurements_with_dem.SURF_WATER_LEVEL,color_nominal='Blue',add_text=True,file_name=f'{date}'\".png\")\n",
        "        #Results.append(measurements_with_dem.SURF_WATER_LEVEL)\n",
        "        Results.append(measurements.SURF_WATER_LEVEL)\n",
        "        dates.append(y)\n",
        "        gdf_detected_water=bathymetry.copy()\n",
        "        intersection=bathymetry['geometry'].intersection(detected_water)\n",
        "        gdf_detected_water['geometry']=intersection\n",
        "\n",
        "        #gdf_detected_water.crs\n",
        "        #EPSG:32636\n",
        "        #WGS 84 / UTM zone 36N\n",
        "        gdf_detected_water=gdf_detected_water.to_crs(32636)\n",
        "\n",
        "        gdf_detected_water['surface'] = gdf_detected_water['geometry'].area\n",
        "\n",
        "        gdf_detected_water['volume']=(sensor_water_level - gdf_detected_water['moydepth'])*gdf_detected_water['surface']\n",
        "        print(date, sensor_water_level, measurements.SURF_WATER_LEVEL, gdf_detected_water['surface'].sum(), gdf_detected_water['volume'].sum())\n",
        "        #shpfilename = \"gdrive/My Drive/CNRS/hdd/Qaraaoun/results/WaterDetection\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        #shpfilename = \"/content/water-observatory-backend/src/models/WaterDetection\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        #gdf_detected_water.to_file('%s.shp' % shpfilename)\n",
        "        time.sleep(1)\n",
        "\n",
        "      except Exception as inst:\n",
        "          print(\"Error processing Sentinel image for date: \", date)\n",
        "          print(type(inst))    # the exception instance\n",
        "          print(inst.args)     # arguments stored in .args\n",
        "          print(inst)          #  __str__ allows args to be printed directly, but may be overridden in exception subclasse\n",
        "\n",
        "    else:\n",
        "      print(\"Cannot request image for date: \", date)\n",
        "\n",
        "  else:\n",
        "      print(\"Sensor Water Level is not avaialble for date: \", date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSFAf_8MIs-B"
      },
      "source": [
        "#**Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o7QTpgSvMA5"
      },
      "source": [
        "#check the quality of regression model\n",
        "#Visual analytics and diagnostics of model fit for linear regression\n",
        "# checking the goodness of fit by verifying the fundamental assumptions of linear regression: linearity, independence, constant variance, and normality.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.formula.api as sm\n",
        "from seaborn import pairplot\n",
        "from statsmodels.graphics.correlation import plot_corr\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from scipy.stats import shapiro\n",
        "from statsmodels.stats.outliers_influence import OLSInfluence as influence\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
        "\n",
        "\n",
        "df_dataset = pd.read_excel('/content/qaraaoun-reservoir/src/models/results.xlsx')\n",
        "\n",
        "#df_dataset.describe().T\n",
        "\n",
        "#X = df_dataset['TotalWaterSurface']\n",
        "X = df_dataset['WaterSurfacePercentage']\n",
        "y = df_dataset['TotalWaterVolume']\n",
        "\n",
        "#NaN values to be removed:\n",
        "X = X.dropna()\n",
        "y = y.dropna()\n",
        "\n",
        "#Taking a peek at the relationship between the predicting variable and the response\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(x = X, y = y, color = 'blue', edgecolor = 'k')\n",
        "plt.grid(True)\n",
        "plt.title('TotalWaterSurface vs. TotalWaterVolume', fontsize=16)\n",
        "plt.xlabel('TotalWaterSurface', fontsize=14)\n",
        "plt.ylabel('TotalWaterVolume\\n(M3, meter cubes)', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "#Pairwise scatter plots\n",
        "pairplot(df_dataset[['TotalWaterSurface', 'TotalWaterVolume']])\n",
        "\n",
        "\n",
        "#Correlation matrix and heatmap to visually check for multicollinearity\n",
        "corr = df_dataset[['TotalWaterSurface', 'TotalWaterVolume']].corr()\n",
        "corr\n",
        "fig=plot_corr(corr,xnames=corr.columns)\n",
        "\n",
        "#Creating a formula string for using in the statsmodels.OLS()\n",
        "formula_str = df_dataset.columns[4]+' ~ ' + df_dataset.columns[3]\n",
        "formula_str\n",
        "#Construct and fit the model. Print summary of the fitted model\n",
        "model = sm.ols(formula = formula_str, data = df_dataset[['TotalWaterSurface', 'TotalWaterVolume']])\n",
        "fitted = model.fit()\n",
        "print(fitted.summary())\n",
        "\n",
        "#A new Result dataframe: p-values and statistical significance of the features\n",
        "df_result=pd.DataFrame()\n",
        "df_result['pvalues'] = fitted.pvalues[1:]\n",
        "df_result['Features'] = df_dataset.columns[3]\n",
        "df_result.set_index('Features',inplace=True)\n",
        "\n",
        "def yes_no(b):\n",
        "    if b:\n",
        "        return 'Yes'\n",
        "    else:\n",
        "        return 'No'\n",
        "\n",
        "\n",
        "df_result['Statistically significant?']= df_result['pvalues'].apply(yes_no)\n",
        "df_result\n",
        "\n",
        "\n",
        "#Residuals vs. predicting variables plots\n",
        "#Conclusion: Residual plots show some bit of clustering but overall the assumptions linearity and independence seem to hold because the distribution seem random around the 0 axis.\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.title(\"TotalWaterSurface vs. \\nModel residuals\", fontsize = 16)\n",
        "plt.scatter(x= X, y = fitted.resid, color = 'blue', edgecolor = 'k')\n",
        "plt.grid(True)\n",
        "xmin = min(X)\n",
        "xmax = max(X)\n",
        "plt.hlines(y = 0, xmin = xmin*0.9, xmax = xmax*1.1, color = 'red', linestyle = '--', lw = 3)\n",
        "plt.xlabel('TotalWaterSurface', fontsize = 14)\n",
        "plt.ylabel('Residuals', fontsize = 14)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Fitted vs. residuals\n",
        "#Conclusion: does The fitted vs. residuals plot shows violation of the constant variance assumption - Heteroscedasticity?\n",
        "plt.figure(figsize=(8,5))\n",
        "p=plt.scatter(x=fitted.fittedvalues,y=fitted.resid,edgecolor='k')\n",
        "xmin=min(fitted.fittedvalues)\n",
        "xmax = max(fitted.fittedvalues)\n",
        "plt.hlines(y=0,xmin=xmin*0.9,xmax=xmax*1.1,color='red',linestyle='--',lw=3)\n",
        "plt.xlabel(\"Fitted values\",fontsize=15)\n",
        "plt.ylabel(\"Residuals\",fontsize=15)\n",
        "plt.title(\"Fitted vs. residuals plot\",fontsize=18)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#Histogram of normalized residuals\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(fitted.resid_pearson,bins=20,edgecolor='k')\n",
        "plt.ylabel('Count',fontsize=15)\n",
        "plt.xlabel('Normalized residuals',fontsize=15)\n",
        "plt.title(\"Histogram of normalized residuals\",fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "#Q-Q plot of the residuals\n",
        "#The Q-Q plot (and the histogram above) shows that the normality assumption is satisfied pretty good?\n",
        "plt.figure(figsize=(8,5))\n",
        "fig=qqplot(fitted.resid_pearson,line='45',fit='True')\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xlabel(\"Theoretical quantiles\",fontsize=15)\n",
        "plt.ylabel(\"Sample quantiles\",fontsize=15)\n",
        "plt.title(\"Q-Q plot of normalized residuals\",fontsize=18)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#Normality (Shapiro-Wilk) test of the residuals\n",
        "_,p=shapiro(fitted.resid)\n",
        "\n",
        "if p<0.01:\n",
        "    print(\"The residuals seem to come from Gaussian process\")\n",
        "else:\n",
        "    print(\"The normality assumption may not hold\")\n",
        "\n",
        "#Cook's distance (checking for outliers in residuals)\n",
        "#Conclusion: There are few data points with residuals being possible outliers\n",
        "inf=influence(fitted)\n",
        "(c, p) = inf.cooks_distance\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.title(\"Cook's distance plot for the residuals\",fontsize=16)\n",
        "plt.stem(np.arange(len(c)), c, markerfmt=\",\", use_line_collection=True)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "################### VIF Definition #################\n",
        "formula_str = df_dataset.columns[4]+ ' ~ ' + df_dataset.columns[3]\n",
        "formula_str\n",
        "model_mul = sm.ols(formula = formula_str, data = df_dataset[['TotalWaterSurface', 'TotalWaterVolume']]).fit()\n",
        "Vif1 = 1 / (1 - model_mul.rsquared)\n",
        "\n",
        "############# VIF for Multicollinearity ############\n",
        "if 1 < Vif1 <= 4:\n",
        "    print('Fine with light multicollinearity.')\n",
        "elif 4 < Vif1 <= 10:\n",
        "    print('Fine with moderate multicollinearity.')\n",
        "elif Vif1 > 10:\n",
        "    print('Highly multicollinear.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKoN2cVJ1dx"
      },
      "source": [
        "#Design regression model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "df_dataset = pd.read_excel('/content/qaraaoun-reservoir/src/models/results.xlsx')\n",
        "#df_dataset.shape\n",
        "#df_dataset.describe()\n",
        "#df_dataset.info()\n",
        "#df_dataset.dtypes\n",
        "\n",
        "#sns.pairplot(df_dataset, hue='TotalWaterVolume')\n",
        "\n",
        "#X = df_dataset['TotalWaterSurface']\n",
        "X = df_dataset['WaterSurfacePercentage']\n",
        "y = df_dataset['TotalWaterVolume']\n",
        "\n",
        "\n",
        "\n",
        "#NaN values to be removed:\n",
        "X = X.dropna()\n",
        "y = y.dropna()\n",
        "\n",
        "\n",
        "#Splitting the dataset to training and test sets.\n",
        "#Test set will be 20%. used random_state to select records randomly.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Scaling\n",
        "#X_min_max_scaler = preprocessing.MinMaxScaler().fit(X_train.values.reshape(-1,1))\n",
        "#X = X_min_max_scaler.fit_transform(X.values.reshape(-1,1))\n",
        "y_min_max_scaler = preprocessing.MinMaxScaler().fit(y_train.values.reshape(-1,1))\n",
        "#y = y_min_max_scaler.fit_transform(y.values.reshape(-1,1))\n",
        "\n",
        "#X_train = X_min_max_scaler.transform(X_train.values.reshape(-1,1))\n",
        "#X_test = X_min_max_scaler.transform(X_test.values.reshape(-1,1))\n",
        "y_train = y_min_max_scaler.transform(y_train.values.reshape(-1,1))\n",
        "y_test = y_min_max_scaler.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "#y_train=numpy.array(y_train)\n",
        "\n",
        "X_train = X_train.values.reshape(X_train.values.shape[0])\n",
        "X_test = X_test.values.reshape(X_test.values.shape[0])\n",
        "y_train = y_train.reshape(y_train.shape[0])\n",
        "y_test = y_test.reshape(y_test.shape[0])\n",
        "\n",
        "\n",
        "#Feature Scaling\n",
        "#StandardScaler to normally distribute the input features, both train and test data.\n",
        "#This way the data is distributed around 0, with a standard deviation of 1.\n",
        "#sc_X = preprocessing.StandardScaler()\n",
        "#sc_y = preprocessing.StandardScaler()\n",
        "#X_train = sc_X.fit_transform(X_train.values.reshape(-1,1))\n",
        "#X_test = sc_X.transform(X_test.values.reshape(-1,1))\n",
        "#y_train = sc_y.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc_y.fit_transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "#MinMaxScaler normalizes the output variable y between 0 and 1\n",
        "#y.values returns a numpy array\n",
        "#min_max_scaler = preprocessing.MinMaxScaler()\n",
        "#y_scaled = min_max_scaler.fit_transform(y.values.reshape(-1,1))\n",
        "#y = pd.Series(list(y_scaled))\n",
        "#X_min_max_scaler = preprocessing.MinMaxScaler()\n",
        "#X_train = X_min_max_scaler.fit_transform(X_train.values.reshape(-1,1))\n",
        "#X_test = X_min_max_scaler.fit_transform(X_test.values.reshape(-1,1))\n",
        "#y_min_max_scaler = preprocessing.MinMaxScaler()\n",
        "#y_train = y_min_max_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = y_min_max_scaler.fit_transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(6, 5))\n",
        "ax1.set_title('Before Scaling')\n",
        "sns.kdeplot(df_dataset['TotalWaterSurface'].dropna(), ax=ax1)\n",
        "sns.kdeplot(df_dataset['TotalWaterVolume'], ax=ax1)\n",
        "ax2.set_title('After Min-Max Scaling')\n",
        "sns.kdeplot(np.concatenate([X_train, X_test]), ax=ax2)\n",
        "sns.kdeplot(np.concatenate([y_train, y_test]), ax=ax2)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Trying with RobustScaler:\n",
        "#sc_X = preprocessing.RobustScaler()\n",
        "#sc_y = preprocessing.RobustScaler()\n",
        "#X_train = sc_X.fit_transform(X_train.values.reshape(-1,1))\n",
        "#X_test = sc_X.transform(X_test.values.reshape(-1,1))\n",
        "#y_train = sc_y.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc_y.fit_transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "\n",
        "#Generate Model\n",
        "#regr = svm.SVR(kernel = 'rbf')\n",
        "#regr = svm.SVR(kernel = 'rbf', C = 100, epsilon = 0.0005, gamma = 5, degree = 3)\n",
        "#regr = svm.SVR(kernel = 'rbf', C = 500, epsilon = 0.001, gamma = 10, degree = 3)\n",
        "regr = svm.SVR(kernel = 'rbf', C = 1000, epsilon = 0.0004, gamma = 9, degree = 3)\n",
        "\n",
        "\n",
        "#regr = svm.SVR(kernel = 'poly', C = 1000, epsilon = 0.01, gamma = 10, degree = 3)\n",
        "\n",
        "#regr.fit(X_train.values.reshape(-1,1), y_train)\n",
        "regr.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
        "\n",
        "#predict the data\n",
        "#y_pred= regr.predict(X_test.values.reshape(-1,1))\n",
        "y_pred= regr.predict(X_test.reshape(-1, 1))\n",
        "\n",
        "# Save the model to a file in the current working directory\n",
        "pkl_filename = \"/content/qaraaoun-reservoir/src/models/pickle_model.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(regr, file)\n",
        "\n",
        "# save the scaler\n",
        "#pickle.dump(X_min_max_scaler, open('/content/qaraaoun-reservoir/src/models/X_min_max_scaler.pkl', 'wb'))\n",
        "pickle.dump(y_min_max_scaler, open('/content/qaraaoun-reservoir/src/models/y_min_max_scaler.pkl', 'wb'))\n",
        "\n",
        "#Metrics\n",
        "#for classification only not regression\n",
        "#print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
        "#print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
        "#print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
        "#R-squared (co-effecient of determination)\n",
        "print(\"R-squared: \", regr.score(X_test.reshape(-1, 1), y_test.reshape(-1, 1)))\n",
        "#print(metrics.r2_score(y_test,y_pred))\n",
        "#print(regr.predict([[8695866]]))\n",
        "print(\"Mean Absolute Error (MEA): \", metrics.mean_absolute_error(y_test,y_pred))\n",
        "print('Root Mean Squared Error (RMSE): ', math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#Visualising the Support Vector Regression results\n",
        "plt.scatter(X_train, y_train, color = 'red')\n",
        "plt.plot(X_train, regr.predict(X_train.reshape(-1, 1)), color = 'blue')\n",
        "plt.title('Qaraaoun Reservoir Support Vector Regression Model')\n",
        "plt.xlabel('TotalWaterSurface')\n",
        "plt.ylabel('TotalWaterVolume')\n",
        "plt.show()\n",
        "\n",
        "X_grid = np.arange(min(X_train), max(X_train), 0.1)\n",
        "X_grid = X_grid.reshape((len(X_grid), 1))\n",
        "plt.scatter(X_train, y_train, color = 'red')\n",
        "plt.plot(X_grid, regr.predict(X_grid), color = 'blue')\n",
        "plt.title('Qaraaoun Reservoir Support Vector Regression Model')\n",
        "plt.xlabel('TotalWaterSurface')\n",
        "plt.ylabel('TotalWaterVolume')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X_grid = np.arange(min(X_test), max(X_test), 0.1)\n",
        "X_grid = X_grid.reshape((len(X_grid), 1))\n",
        "plt.scatter(X_test, y_test, color = 'red')\n",
        "plt.scatter(X_test, y_pred, color = 'green')\n",
        "plt.plot(X_grid, regr.predict(X_grid), color = 'blue')\n",
        "plt.title('Qaraaoun Reservoir Support Vector Regression Model')\n",
        "plt.xlabel('TotalWaterSurface')\n",
        "plt.ylabel('TotalWaterVolume')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNsWfxx2vdO"
      },
      "source": [
        "#Hyperparameters tunning\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn import svm\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "df_results = pd.read_excel('/content/qaraaoun-reservoir/src/models/results.xlsx')\n",
        "#df_results.info()\n",
        "#sns.pairplot(df_results, hue='TotalWaterVolume')\n",
        "\n",
        "X = df_results['TotalWaterSurface']\n",
        "y = df_results['TotalWaterVolume']\n",
        "\n",
        "#NaN values to be removed:\n",
        "X = X.dropna()\n",
        "y = y.dropna()\n",
        "\n",
        "#Scaling\n",
        "X_min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X = X_min_max_scaler.fit_transform(X.values.reshape(-1,1))\n",
        "y_min_max_scaler = preprocessing.MinMaxScaler()\n",
        "y = y_min_max_scaler.fit_transform(y.values.reshape(-1,1))\n",
        "\n",
        "#X = X.reshape(X.shape[0])\n",
        "#y = y.reshape(y.shape[0])\n",
        "\n",
        "def svr_model(X, y):\n",
        "    gsc = GridSearchCV(\n",
        "        estimator=svm.SVR(kernel='rbf'),\n",
        "        param_grid={\n",
        "            'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 1, 100, 125, 150, 200, 500, 1000],\n",
        "            'epsilon': [0.0001, 0.0004, 0.0005, 0.006, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1, 5, 10],\n",
        "            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5, 6, 7, 8, 9, 10]\n",
        "        },\n",
        "        cv = 10, scoring='neg_mean_squared_error', verbose = 0, n_jobs=-1)\n",
        "\n",
        "    grid_result = gsc.fit(X, y)\n",
        "    print(gsc.best_estimator_)\n",
        "    best_params = grid_result.best_params_\n",
        "    #print(grid_result.best_params_)\n",
        "    best_svr = svm.SVR(kernel='rbf', C=best_params[\"C\"], epsilon=best_params[\"epsilon\"],\n",
        "                       gamma=best_params[\"gamma\"], coef0=0.1, shrinking=True,\n",
        "                       tol=0.001, cache_size=200, verbose=False, max_iter=-1)\n",
        "\n",
        "    scoring = {\n",
        "               'abs_error': 'neg_mean_absolute_error',\n",
        "               'squared_error': 'neg_mean_squared_error'}\n",
        "\n",
        "    scores = cross_validate(best_svr, X, y, cv=10, scoring=scoring, return_train_score=True)\n",
        "\n",
        "    return \"MAE :\", abs(scores['test_abs_error'].mean()), \"| RMSE :\", math.sqrt(abs(scores['test_squared_error'].mean()))\n",
        "\n",
        "\n",
        "# Run\n",
        "print(svr_model(X,y))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}